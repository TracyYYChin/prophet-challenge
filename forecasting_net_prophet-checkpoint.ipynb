{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLcqr6BM12Ty"
   },
   "source": [
    "# Forecasting Net Prophet\n",
    "\n",
    "You’re a growth analyst at [MercadoLibre](http://investor.mercadolibre.com/about-us). With over 200 million users, MercadoLibre is the most popular e-commerce site in Latin America. You've been tasked with analyzing the company's financial and user data in clever ways to make the company grow. So, you want to find out if the ability to predict search traffic can translate into the ability to successfully trade the stock.\n",
    "\n",
    "The instructions for this Challenge are divided into four steps, as follows:\n",
    "\n",
    "* Step 1: Find unusual patterns in hourly Google search traffic\n",
    "\n",
    "* Step 2: Mine the search traffic data for seasonality\n",
    "\n",
    "* Step 3: Relate the search traffic to stock price patterns\n",
    "\n",
    "* Step 4: Create a time series model with Prophet\n",
    "\n",
    "The following subsections detail these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvLM4Muf12T6"
   },
   "source": [
    "## Install and import the required libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jETJBREQ16et",
    "outputId": "94bebe36-b681-4cac-d430-28ce831d86a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prophet in c:\\users\\tracy\\anaconda3\\lib\\site-packages (1.1.5)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from prophet) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from prophet) (1.26.2)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from prophet) (3.8.0)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from prophet) (2.1.1)\n",
      "Requirement already satisfied: holidays>=0.25 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from prophet) (0.42)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from prophet) (4.65.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from prophet) (6.1.1)\n",
      "Requirement already satisfied: stanio~=0.3.0 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.3.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from holidays>=0.25->prophet) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tracy\\anaconda3\\lib\\site-packages (from python-dateutil->holidays>=0.25->prophet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install the required libraries\n",
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "qnzrTQf512T7",
    "outputId": "1e0d1cfb-12d2-4991-8fba-883a5f58fdd0"
   },
   "outputs": [],
   "source": [
    "# Import the required libraries and dependencies\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNPLnTzk12T-"
   },
   "source": [
    "## Step 1: Find Unusual Patterns in Hourly Google Search Traffic\n",
    "\n",
    "The data science manager asks if the Google search traffic for the company links to any financial events at the company. Or, does the search traffic data just present random noise? To answer this question, pick out any unusual patterns in the Google search data for the company, and connect them to the corporate financial events.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Read the search data into a DataFrame, and then slice the data to just the month of May 2020. (During this month, MercadoLibre released its quarterly financial results.) Visualize the results. Do any unusual patterns exist?\n",
    "\n",
    "2. Calculate the total search traffic for the month, and then compare the value to the monthly median across all months. Did the Google search traffic increase during the month that MercadoLibre released its financial results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgT_j6J412T-"
   },
   "source": [
    "#### Step 1: Read the search data into a DataFrame, and then slice the data to just the month of May 2020. (During this month, MercadoLibre released its quarterly financial results.) Visualize the results. Do any unusual patterns exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "cztyn4NK12T_",
    "outputId": "efdc489a-fe30-4300-acdb-6f6e5374f885"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tracy\\AppData\\Local\\Temp\\ipykernel_21060\\3734881759.py:4: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  df_mercado_trends = pd.read_csv(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"6/1/16 0:00\" doesn't match format \"%Y-%m-%d %H:%M:%S\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1176\u001b[0m, in \u001b[0;36m_make_date_converter.<locals>.converter\u001b[1;34m(col, *date_cols)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*parsing datetimes with mixed time zones \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill raise a warning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1173\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[0;32m   1175\u001b[0m     result \u001b[38;5;241m=\u001b[39m tools\u001b[38;5;241m.\u001b[39mto_datetime(\n\u001b[1;32m-> 1176\u001b[0m         date_parser(\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;241m*\u001b[39m(unpack_if_single_element(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m date_cols)\n\u001b[0;32m   1178\u001b[0m         ),\n\u001b[0;32m   1179\u001b[0m         errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1180\u001b[0m         cache\u001b[38;5;241m=\u001b[39mcache_dates,\n\u001b[0;32m   1181\u001b[0m     )\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, datetime\u001b[38;5;241m.\u001b[39mdatetime):\n",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Store the data in a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Set the \"Date\" column as the Datetime Index.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df_mercado_trends \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://static.bc-edx.com/ai/ail-v-1-0/m8/lms/datasets/google_hourly_search_trends.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      7\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# infer_datetime_format=True  # Remove this argument\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Specify datetime format explicitly to avoid warning\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     date_parser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mto_datetime(x, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m )\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Review the first and last five rows of the DataFrame\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1144\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1144\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    491\u001b[0m     arg,\n\u001b[0;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03mCall array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m result, timezones \u001b[38;5;241m=\u001b[39m array_strptime(arg, fmt, exact\u001b[38;5;241m=\u001b[39mexact, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n",
      "File \u001b[1;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"6/1/16 0:00\" doesn't match format \"%Y-%m-%d %H:%M:%S\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Store the data in a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Set the \"Date\" column as the Datetime Index.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df_mercado_trends \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://static.bc-edx.com/ai/ail-v-1-0/m8/lms/datasets/google_hourly_search_trends.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      7\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# infer_datetime_format=True  # Remove this argument\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Specify datetime format explicitly to avoid warning\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     date_parser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mto_datetime(x, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m )\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Review the first and last five rows of the DataFrame\u001b[39;00m\n\u001b[0;32m     14\u001b[0m display(df_mercado_trends\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m         nrows\n\u001b[0;32m   1750\u001b[0m     )\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:333\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    330\u001b[0m     data \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, (i, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(names, data_tups)}\n\u001b[0;32m    332\u001b[0m     names, date_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_date_conversions(names, data)\n\u001b[1;32m--> 333\u001b[0m     index, column_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_index(date_data, alldata, names)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index, column_names, date_data\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:371\u001b[0m, in \u001b[0;36mParserBase._make_index\u001b[1;34m(self, data, alldata, columns, indexnamerow)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_complex_date_col:\n\u001b[0;32m    370\u001b[0m     simple_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_simple_index(alldata, columns)\n\u001b[1;32m--> 371\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_index(simple_index)\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_complex_date_col:\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_processed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:468\u001b[0m, in \u001b[0;36mParserBase._agg_index\u001b[1;34m(self, index, try_parse_dates)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(index):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m try_parse_dates \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_parse_dates(i):\n\u001b[1;32m--> 468\u001b[0m         arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_date_conv(\n\u001b[0;32m    469\u001b[0m             arr,\n\u001b[0;32m    470\u001b[0m             col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names[i] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    471\u001b[0m         )\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_filter:\n\u001b[0;32m    474\u001b[0m         col_na_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_values\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1194\u001b[0m, in \u001b[0;36m_make_date_converter.<locals>.converter\u001b[1;34m(col, *date_cols)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   1187\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*parsing datetimes with mixed time zones \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill raise a warning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1191\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1192\u001b[0m     )\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tools\u001b[38;5;241m.\u001b[39mto_datetime(\n\u001b[1;32m-> 1194\u001b[0m         parsing\u001b[38;5;241m.\u001b[39mtry_parse_dates(\n\u001b[0;32m   1195\u001b[0m             parsing\u001b[38;5;241m.\u001b[39mconcat_date_cols(date_cols),\n\u001b[0;32m   1196\u001b[0m             parser\u001b[38;5;241m=\u001b[39mdate_parser,\n\u001b[0;32m   1197\u001b[0m         ),\n\u001b[0;32m   1198\u001b[0m         errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1199\u001b[0m     )\n",
      "File \u001b[1;32mparsing.pyx:764\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.try_parse_dates\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Store the data in a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Set the \"Date\" column as the Datetime Index.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df_mercado_trends \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://static.bc-edx.com/ai/ail-v-1-0/m8/lms/datasets/google_hourly_search_trends.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      7\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# infer_datetime_format=True  # Remove this argument\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Specify datetime format explicitly to avoid warning\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     date_parser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mto_datetime(x, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m )\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Review the first and last five rows of the DataFrame\u001b[39;00m\n\u001b[0;32m     14\u001b[0m display(df_mercado_trends\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1146\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1146\u001b[0m     result \u001b[38;5;241m=\u001b[39m convert_listlike(np\u001b[38;5;241m.\u001b[39marray([arg]), \u001b[38;5;28mformat\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mbool_):\n\u001b[0;32m   1148\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(result)  \u001b[38;5;66;03m# TODO: avoid this kludge.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    491\u001b[0m     arg,\n\u001b[0;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    509\u001b[0m     arg,\n\u001b[0;32m    510\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m array_strptime(arg, fmt, exact\u001b[38;5;241m=\u001b[39mexact, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"6/1/16 0:00\" doesn't match format \"%Y-%m-%d %H:%M:%S\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Store the data in a Pandas DataFrame\n",
    "# Set the \"Date\" column as the Datetime Index.\n",
    "\n",
    "df_mercado_trends = pd.read_csv(\n",
    "    \"https://static.bc-edx.com/ai/ail-v-1-0/m8/lms/datasets/google_hourly_search_trends.csv\",\n",
    "    index_col='Date', \n",
    "    parse_dates=True, \n",
    "    # infer_datetime_format=True  # Remove this argument\n",
    "    # Specify datetime format explicitly to avoid warning\n",
    "    date_parser=lambda x: pd.to_datetime(x, format='%Y-%m-%d %H:%M:%S')\n",
    ").dropna()\n",
    "\n",
    "# Review the first and last five rows of the DataFrame\n",
    "display(df_mercado_trends.head())\n",
    "display(df_mercado_trends.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfm0FSiF12T_",
    "outputId": "aded2e4c-06d4-424e-8d55-185cad8b052e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_mercado_trends' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Review the data types of the DataFrame using the info function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_mercado_trends\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_mercado_trends' is not defined"
     ]
    }
   ],
   "source": [
    "# Review the data types of the DataFrame using the info function\n",
    "df_mercado_trends.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "3HSQMhNK12T_",
    "outputId": "62c34d5d-5759-4f96-a226-fba0473c30f4"
   },
   "outputs": [],
   "source": [
    "# Slice the DataFrame to just the month of May 2020\n",
    "df_may_2020 = df_mercado_trends['2020-05']\n",
    "\n",
    "# Plot to visualize the data for May 2020\n",
    "df_may_2020.plot(figsize=(10, 6), title='Hourly Search Trends - May 2020')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo9y14TY12UA"
   },
   "source": [
    "#### Step 2: Calculate the total search traffic for the month, and then compare the value to the monthly median across all months. Did the Google search traffic increase during the month that MercadoLibre released its financial results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EimOMwen12UA",
    "outputId": "bc6b258a-70d3-4ce2-ff40-36e4ec0a6a26"
   },
   "outputs": [],
   "source": [
    "# Calculate the sum of the total search traffic for May 2020\n",
    "traffic_may_2020 = df_may_2020.sum()\n",
    "\n",
    "\n",
    "# View the traffic_may_2020 value\n",
    "traffic_may_2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4B9WQ2O12UB",
    "outputId": "eac9476c-60ac-43ab-d974-65988744c9cb"
   },
   "outputs": [],
   "source": [
    "# Calcluate the monhtly median search traffic across all months \n",
    "median_monthly_traffic = df_mercado_trends.resample('M').sum().median()\n",
    "\n",
    "\n",
    "# Group the DataFrame by index year and then index month, chain the sum and then the median functions\n",
    "\n",
    "\n",
    "# View the median_monthly_traffic value\n",
    "median_monthly_traffic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaUKnq1e12UB",
    "outputId": "da865e4b-8aed-45d1-fb98-ed50abb7e607"
   },
   "outputs": [],
   "source": [
    "# To compare the seach traffic for the month of May 2020 to the overall monthly median value,\n",
    "# Divide the may traffic total by the median monthly traffic\n",
    "traffic_may_2020/median_monthly_traffic\n",
    "\n",
    "traffic_may_2020 / median_monthly_traffic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FzTTGQ-12UC"
   },
   "source": [
    "##### Answer the following question: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG979D-v12UC"
   },
   "source": [
    "**Question:** Did the Google search traffic increase during the month that MercadoLibre released its financial results?\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvwtfvC112UC"
   },
   "source": [
    "## Step 2: Mine the Search Traffic Data for Seasonality\n",
    "\n",
    "Marketing realizes that they can use the hourly search data, too. If they can track and predict interest in the company and its platform for any time of day, they can focus their marketing efforts around the times that have the most traffic. This will get a greater return on investment (ROI) from their marketing budget.\n",
    "\n",
    "To that end, you want to mine the search traffic data for predictable seasonal patterns of interest in the company. To do so, complete the following steps:\n",
    "\n",
    "1. Group the hourly search data to plot the average traffic by the hour of day. Does the search traffic peak at a particular time of day or is it relatively consistent?\n",
    "\n",
    "2. Group the hourly search data to plot the average traffic by the day of the week (for example, Monday vs. Friday). Does the search traffic get busiest on any particular day of the week?\n",
    "\n",
    "3. Group the hourly search data to plot the average traffic by the week of the year. Does the search traffic tend to increase during the winter holiday period (weeks 40 through 52)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Group the hourly search data to plot the average traffic by the hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the hourly search data to plot the average traffic by the day of week \n",
    "df_mercado_trends.groupby(df_mercado_trends.index.dayofweek).mean().plot(kind='bar', figsize=(10, 6), title='Average Hourly Search Traffic by Day of Week')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBoKE-Kx12UC"
   },
   "source": [
    "#### Step 2: Group the hourly search data to plot the average traffic by the day of the week (for example, Monday vs. Friday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "c3z3n5Mg12UD",
    "outputId": "0eb89615-f6ed-44d4-df69-2aeb2236be5f"
   },
   "outputs": [],
   "source": [
    "# Group the hourly search data to plot the average traffic by the day of week \n",
    "df_mercado_trends.groupby(df_mercado_trends.index.week).mean().plot(kind='bar', figsize=(10, 6), title='Average Hourly Search Traffic by Week of the Year')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Group the hourly search data to plot the average traffic by the week of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the hourly search data to plot the average traffic by the week of the year \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8rZ9rS612UE"
   },
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZneaiiW-12UE"
   },
   "source": [
    "**Question:** Are there any time based trends that you can see in the data?\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fI9MdNR512UG"
   },
   "source": [
    "## Step 3: Relate the Search Traffic to Stock Price Patterns\n",
    "\n",
    "You mention your work on the search traffic data during a meeting with people in the finance group at the company. They want to know if any relationship between the search data and the company stock price exists, and they ask if you can investigate.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Read in and plot the stock price data. Concatenate the stock price data to the search data in a single DataFrame.\n",
    "\n",
    "2. Market events emerged during the year of 2020 that many companies found difficult. But, after the initial shock to global financial markets, new customers and revenue increased for e-commerce platforms. Slice the data to just the first half of 2020 (`2020-01` to `2020-06` in the DataFrame), and then plot the data. Do both time series indicate a common trend that’s consistent with this narrative?\n",
    "\n",
    "3. Create a new column in the DataFrame named “Lagged Search Trends” that offsets, or shifts, the search traffic by one hour. Create two additional columns:\n",
    "\n",
    "    * “Stock Volatility”, which holds an exponentially weighted four-hour rolling average of the company’s stock volatility\n",
    "\n",
    "    * “Hourly Stock Return”, which holds the percent change of the company's stock price on an hourly basis\n",
    "\n",
    "4. Review the time series correlation, and then answer the following question: Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqkIVUU_12UG"
   },
   "source": [
    "#### Step 1: Read in and plot the stock price data. Concatenate the stock price data to the search data in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "rKAzc9ew12UG",
    "outputId": "30bd97fb-945f-449b-e267-51ba93bbf06a"
   },
   "outputs": [],
   "source": [
    "# Upload the \"mercado_stock_price.csv\" file into Colab, then store in a Pandas DataFrame\n",
    "# Set the \"date\" column as the Datetime Index.\n",
    "df_mercado_stock = pd.read_csv(\n",
    "    \"https://static.bc-edx.com/ai/ail-v-1-0/m8/lms/datasets/mercado_stock_price.csv\",\n",
    "    index_col=\"date\",\n",
    "    parse_dates=True, \n",
    "    infer_datetime_format=True\n",
    ").dropna()\n",
    "\n",
    "# View the first and last five rows of the DataFrame\n",
    "display(df_mercado_stock.head())\n",
    "display(df_mercado_stock.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "gPMCkpIB12UH",
    "outputId": "1116c30b-7901-4268-fddc-9acf50fc0ebc"
   },
   "outputs": [],
   "source": [
    "# Visualize the closing price of the df_mercado_stock DataFrame\n",
    "df_mercado_stock['close'].plot(figsize=(10, 6), title='Closing Price of Mercado Stock')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "5Mt44bD512UH",
    "outputId": "bdd5cac6-9ddd-4b51-a21e-f3798267ee2b"
   },
   "outputs": [],
   "source": [
    "# Concatenate the df_mercado_stock DataFrame with the df_mercado_trends DataFrame\n",
    "merged_df = pd.concat([df_mercado_stock, df_mercado_trends], axis=1).dropna()\n",
    "\n",
    "# Concatenate the DataFrame by columns (axis=1), and drop and rows with only one column of data\n",
    "\n",
    "\n",
    "# View the first and last five rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWaMSI4U12UI"
   },
   "source": [
    "#### Step 2: Market events emerged during the year of 2020 that many companies found difficult. But, after the initial shock to global financial markets, new customers and revenue increased for e-commerce platforms. Slice the data to just the first half of 2020 (`2020-01` to `2020-06` in the DataFrame), and then plot the data. Do both time series indicate a common trend that’s consistent with this narrative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "1KTYdkfK12UI",
    "outputId": "308f0e4b-f460-4ed0-f25b-00fc2ab1a6ef"
   },
   "outputs": [],
   "source": [
    "# For the combined dataframe, slice to just the first half of 2020 (2020-01 through 2020-06) \n",
    "first_half_2020 = merged_df['2020-01':'2020-06']\n",
    "\n",
    "\n",
    "# View the first and last five rows of first_half_2020 DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "bynt-3QV12UI",
    "outputId": "03e29e01-7555-4db5-cddc-e5e79e554930"
   },
   "outputs": [],
   "source": [
    "# Visualize the close and Search Trends data\n",
    "# Plot each column on a separate axes using the following syntax\n",
    "# `plot(subplots=True)`\n",
    "first_half_2020.plot(subplots=True, figsize=(12, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnrxcTZT12UI"
   },
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBkC9MNX12UJ"
   },
   "source": [
    "**Question:** Do both time series indicate a common trend that’s consistent with this narrative?\n",
    "\n",
    "**Answer:** In truth, our evidence of a common trend between search activity and stock price is pretty limited. It does appear generally however that the low point for Mercado Libre's stock price, late March to early April, did coincide with lower search activity for the firm. Search activity does pick up along with its stock price, although the stock price from mid-April onward definitively outpaces search interest.\n",
    "\n",
    "There's one important thing to note: if you zoom in both graphs to the spike around May 5th, 2020, you'll find the date of the company's earnings release to the public. It looks like search traffic for the firm spiked about two hours before the firm's stock price spiked. This could indicate a predictable pattern (can Google Searches predict the stock price?), but an alternative explanation might just be that people tend to search for more information about the firm right before an earnings announcement gets released. We'd need to do a little more time-series research to see which explanation best fits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MDbU6SD12UJ"
   },
   "source": [
    "#### Step 3: Create a new column in the DataFrame named “Lagged Search Trends” that offsets, or shifts, the search traffic by one hour. Create two additional columns:\n",
    "\n",
    "* “Stock Volatility”, which holds an exponentially weighted four-hour rolling average of the company’s stock volatility\n",
    "\n",
    "* “Hourly Stock Return”, which holds the percent change of the company's stock price on an hourly basis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNFBId1812UJ"
   },
   "outputs": [],
   "source": [
    "# Create a new column in the mercado_stock_trends_df DataFrame called Lagged Search Trends\n",
    "# This column should shift the Search Trends information by one hour\n",
    "merged_df['Lagged Search Trends'] = merged_df['Search Trends'].shift(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySKeTjVY12UJ"
   },
   "outputs": [],
   "source": [
    "# Create a new column in the mercado_stock_trends_df DataFrame called Stock Volatility\n",
    "# This column should calculate the standard deviation of the closing stock price return data over a 4 period rolling window\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "jIJOEdlS12UJ",
    "outputId": "a3cef7d4-0397-4c20-c0e4-9ab33ad0c5f8"
   },
   "outputs": [],
   "source": [
    "# Visualize the stock volatility\n",
    "\n",
    "merged_df['Stock Volatility'].plot(figsize=(10, 6), title='Stock Volatility')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FffeBt-w12UK"
   },
   "source": [
    "**Solution Note:** Note how volatility spiked, and tended to stay high, during the first half of 2020. This is a common characteristic of volatility in stock returns worldwide: high volatility days tend to be followed by yet more high volatility days. When it rains, it pours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRBDj-I012UK"
   },
   "outputs": [],
   "source": [
    "# Create a new column in the mercado_stock_trends_df DataFrame called Hourly Stock Return\n",
    "# This column should calculate hourly return percentage of the closing price\n",
    "\n",
    "merged_df['Hourly Stock Return'] = merged_df['close'].pct_change() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "e8_dQ_tT12UK",
    "outputId": "5822c5d4-aeba-4b3f-d0bb-4609bdb37f88"
   },
   "outputs": [],
   "source": [
    "# View the first and last five rows of the mercado_stock_trends_df DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ijd-NMF12UK"
   },
   "source": [
    "#### Step 4: Review the time series correlation, and then answer the following question: Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "SBTDo89212UK",
    "outputId": "96775cf8-0847-430f-8e0b-a1d4adb87996"
   },
   "outputs": [],
   "source": [
    "# Construct correlation table of Stock Volatility, Lagged Search Trends, and Hourly Stock Return\n",
    "correlation_table = merged_df[['Stock Volatility', 'Lagged Search Trends', 'Hourly Stock Return']].corr()\n",
    "print(correlation_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-GH17Lx12UL"
   },
   "source": [
    "##### Answer the following question:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDe24Tla12UL"
   },
   "source": [
    "**Question:** Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?\n",
    "\n",
    "**Answer:** If we read down the second column (or read along the second row), we see that there's a slight negative correlation between searches for the firm and its subsequent stock volatility. More searches (slightly) tend to indicate less near-term hourly stock risk for the firm.\n",
    "\n",
    "On the other hand, there's a positive correlation between search activity in one hour and stock returns in the next: as search activity goes up, so will the firm's stock price in the short term. This effect is very weak though, only half the size of the effect on stock volatility. With the correlation so close to zero, some might also say that there's almost no relationship between these two variables whatsoever, and that the small findings that we do have could be just due to chance. While there's no required threshold when looking at correlation between stock returns and the variables used to predict them, it does tend to be that correlations in this context tend to be very low across the board. It's hard to predict the market!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pK2MFUk12UL"
   },
   "source": [
    "## Step 4: Create a Time Series Model with Prophet\n",
    "\n",
    "Now, you need to produce a time series model that analyzes and forecasts patterns in the hourly search data. To do so, complete the following steps:\n",
    "\n",
    "1. Set up the Google search data for a Prophet forecasting model.\n",
    "\n",
    "2. After estimating the model, plot the forecast. How's the near-term forecast for the popularity of MercadoLibre?\n",
    "\n",
    "3. Plot the individual time series components of the model to answer the following questions:\n",
    "\n",
    "    * What time of day exhibits the greatest popularity?\n",
    "\n",
    "    * Which day of the week gets the most search traffic?\n",
    "\n",
    "    * What's the lowest point for search traffic in the calendar year?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBewkPew12UL"
   },
   "source": [
    "#### Step 1: Set up the Google search data for a Prophet forecasting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "NQ69E7pl12UL",
    "outputId": "015a5dd1-70f0-4272-fb97-3d6a998d0ee2"
   },
   "outputs": [],
   "source": [
    "# Using the df_mercado_trends DataFrame, reset the index so the date information is no longer the index\n",
    "\n",
    "df_mercado_trends.reset_index(inplace=True)\n",
    "\n",
    "# Label the columns ds and y so that the syntax is recognized by Prophet\n",
    "\n",
    "prophet_df = df_mercado_trends.rename(columns={'Date': 'ds', 'Search Trends': 'y'})\n",
    "\n",
    "# Drop an NaN values from the prophet_df DataFrame\n",
    "prophet_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# View the first and last five rows of the mercado_prophet_df DataFrame\n",
    "\n",
    "display(merged_df.head())\n",
    "display(merged_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXemEAJm12UM",
    "outputId": "61091251-f849-4ed7-fa02-4c5b73be6bed"
   },
   "outputs": [],
   "source": [
    "# Call the Prophet function, store as an object\n",
    "m = Prophet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bou0iwL12UM",
    "outputId": "2264802b-10bf-468f-bf94-3f31b286adf8"
   },
   "outputs": [],
   "source": [
    "# Fit the time-series model.\n",
    "m.fit(prophet_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "BtJ5oDPE12UM",
    "outputId": "838b738c-577c-44f5-86be-e6441618600f"
   },
   "outputs": [],
   "source": [
    "# Create a future dataframe to hold predictions\n",
    "# Make the prediction go out as far as 2000 hours (approx 80 days)\n",
    "\n",
    "future_mercado_trends = m.make_future_dataframe(periods=2000, freq='H')\n",
    "\n",
    "# View the last five rows of the future_mercado_trends DataFrame\n",
    "display(future_mercado_trends.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "-JVSYE6C12UN",
    "outputId": "5350b994-ced6-4787-c63a-54eb3030752f"
   },
   "outputs": [],
   "source": [
    "# Make the predictions for the trend data using the future_mercado_trends DataFrame\n",
    "forecast_mercado_trends = m.predict(future_mercado_trends)\n",
    "\n",
    "\n",
    "# Display the first five rows of the forecast_mercado_trends DataFrame\n",
    "display(forecast_mercado_trends.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5jjK41T12UN"
   },
   "source": [
    "#### Step 2: After estimating the model, plot the forecast. How's the near-term forecast for the popularity of MercadoLibre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "wNf28QS212UN",
    "outputId": "d6656095-1878-4101-d59d-60a8edd3da38"
   },
   "outputs": [],
   "source": [
    "# Plot the Prophet predictions for the Mercado trends data\n",
    "fig = m.plot(forecast_mercado_trends)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3twBdEn12UO"
   },
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDsZWZwE12UO"
   },
   "source": [
    "**Question:**  How's the near-term forecast for the popularity of MercadoLibre?\n",
    "\n",
    "**Answer:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY3-VMd612UO"
   },
   "source": [
    "#### Step 3: Plot the individual time series components of the model to answer the following questions:\n",
    "\n",
    "* What time of day exhibits the greatest popularity?\n",
    "\n",
    "* Which day of the week gets the most search traffic?\n",
    "\n",
    "* What's the lowest point for search traffic in the calendar year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "4r31Spg-12UO",
    "outputId": "788447f2-df52-49f1-d34f-8f371e94f643"
   },
   "outputs": [],
   "source": [
    "# Set the index in the forecast_mercado_trends DataFrame to the ds datetime column\n",
    "\n",
    "forecast_mercado_trends.set_index('ds', inplace=True)\n",
    "\n",
    "# View the only the yhat,yhat_lower and yhat_upper columns from the DataFrame\n",
    "forecast_mercado_trends[['yhat', 'yhat_lower', 'yhat_upper']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSAl_1m812UO"
   },
   "source": [
    "Solutions Note: `yhat` represents the most likely (average) forecast, whereas `yhat_lower` and `yhat_upper` represents the worst and best case prediction (based on what are known as 95% confidence intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "qYJDjsb312UP",
    "outputId": "da09564d-92be-4f66-c3d2-9b302531db90"
   },
   "outputs": [],
   "source": [
    "# From the forecast_mercado_trends DataFrame, plot the data to visualize\n",
    "#  the yhat, yhat_lower, and yhat_upper columns over the last 2000 hours \n",
    "\n",
    "forecast_mercado_trends[['yhat', 'yhat_lower', 'yhat_upper']].iloc[-2000:].plot(figsize=(12, 6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873
    },
    "id": "eetFbEwC12UP",
    "outputId": "ff8e7c9b-95bc-4bf7-ad9f-3e2e571be1ae"
   },
   "outputs": [],
   "source": [
    "# Reset the index in the forecast_mercado_trends DataFrame\n",
    "forecast_mercado_trends.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# Use the plot_components function to visualize the forecast results \n",
    "# for the forecast_canada DataFrame \n",
    "m.plot_components(forecast_mercado_trends)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xan9nO9O12UP"
   },
   "source": [
    "##### Answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmWgULWo12UQ"
   },
   "source": [
    "**Question:** What time of day exhibits the greatest popularity?\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkkXUATk12UQ"
   },
   "source": [
    "**Question:** Which day of week gets the most search traffic? \n",
    "   \n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUeR3iHu12UQ"
   },
   "source": [
    "**Question:** What's the lowest point for search traffic in the calendar year?\n",
    "\n",
    "**Answer:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "forecasting_net_prophet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
